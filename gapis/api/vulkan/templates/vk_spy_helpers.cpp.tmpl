{{/*
 * Copyright (C) 2017 Google Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */}}

{{/* ---- Includes ---- */}}
{{Include "../../templates/cpp_common.tmpl"}}

{{$filename := print (Global "API") "_spy_helpers.cpp" }}
{{$ | Macro "Exports" | Reflow 4 | Write $filename}}

{{define "Exports"}}
  {{AssertType $ "API"}}

{{Template "C++.Copyright"}}
¶
#include "gapii/cc/vulkan_exports.h"
#include "gapii/cc/vulkan_extras.h"
#include "gapii/cc/vulkan_types.h"
#include "gapii/cc/vulkan_layer_extras.h"
#include "gapii/cc/vulkan_imports.h"
#include "gapii/cc/vulkan_spy.h"
¶
extern "C" {«
// For this to function on Android the entry-point names for GetDeviceProcAddr
// and GetInstanceProcAddr must be ${layer_name}/Get*ProcAddr.
// This is a bit surprising given that we *MUST* also export
// vkEnumerate*Layers without any prefix.
VK_LAYER_EXPORT VKAPI_ATTR gapii::PFN_vkVoidFunction VKAPI_CALL
gapid_vkGetDeviceProcAddr(gapii::VkDevice dev, const char *funcName) {
    return gapii::vkGetDeviceProcAddr(dev, funcName);
}

VK_LAYER_EXPORT VKAPI_ATTR gapii::PFN_vkVoidFunction VKAPI_CALL
gapid_vkGetInstanceProcAddr(gapii::VkInstance instance, const char *funcName) {
    return gapii::vkGetInstanceProcAddr(instance, funcName);
}

// Documentation is sparse for android, looking at libvulkan.so
// These 4 function must be defined in order for this to even
// be considered for loading.
VK_LAYER_EXPORT VKAPI_ATTR uint32_t VKAPI_CALL
gapid_vkEnumerateInstanceLayerProperties(uint32_t *pCount,
gapii::VkLayerProperties *pProperties) {
    return gapii::vkEnumerateInstanceLayerProperties(pCount, pProperties);
}

// On Android this must also be defined, even if we have 0
// layers to expose.
VK_LAYER_EXPORT VKAPI_ATTR uint32_t VKAPI_CALL
gapid_vkEnumerateInstanceExtensionProperties(const char *pLayerName, uint32_t *pCount,
    gapii::VkExtensionProperties *pProperties) {
        return gapii::vkEnumerateInstanceExtensionProperties(pLayerName, pCount, pProperties);
}

VK_LAYER_EXPORT VKAPI_ATTR uint32_t VKAPI_CALL
gapid_vkEnumerateDeviceLayerProperties(gapii::VkPhysicalDevice device, uint32_t *pCount,
gapii::VkLayerProperties *pProperties) {
    return gapii::vkEnumerateDeviceLayerProperties(device, pCount, pProperties);
}

// On android this must also be defined, even if we have 0
// layers to expose.
VK_LAYER_EXPORT VKAPI_ATTR uint32_t VKAPI_CALL
gapid_vkEnumerateDeviceExtensionProperties(gapii::VkPhysicalDevice device, const char *pLayerName, uint32_t *pCount,
gapii::VkExtensionProperties *pProperties) {
    return gapii::vkEnumerateDeviceExtensionProperties(device, pLayerName, pCount, pProperties);
}
}

namespace gapii {
uint32_t VulkanSpy::SpyOverride_vkEnumerateInstanceLayerProperties(uint32_t *pCount, VkLayerProperties *pProperties) {
    if (pProperties == NULL) {
        *pCount = 1;
        return VkResult::VK_SUCCESS;
    }
    if (pCount == 0) {
        return VkResult::VK_INCOMPLETE;
    }
    *pCount = 1;
    memset(pProperties, 0x00, sizeof(*pProperties));
    strcpy((char*)pProperties->mlayerName, "VkGraphicsSpy");
    pProperties->mspecVersion = VK_VERSION_MAJOR(1) | VK_VERSION_MINOR(0) | 5;
    pProperties->mimplementationVersion = 1;
    strcpy((char*)pProperties->mdescription, "vulkan_trace");
    return VkResult::VK_SUCCESS;
}

uint32_t VulkanSpy::SpyOverride_vkEnumerateDeviceLayerProperties(VkPhysicalDevice dev, uint32_t *pCount, VkLayerProperties *pProperties) {
    if (pProperties == NULL) {
       *pCount = 1;
       return VkResult::VK_SUCCESS;
    }
    if (pCount == 0) {
       return VkResult::VK_INCOMPLETE;
    }
    *pCount = 1;
    memset(pProperties, 0x00, sizeof(*pProperties));
    strcpy((char*)pProperties->mlayerName, "VkGraphicsSpy");
    pProperties->mspecVersion = VK_VERSION_MAJOR(1) | VK_VERSION_MINOR(0) | 5;
    pProperties->mimplementationVersion = 1;
    strcpy((char*)pProperties->mdescription, "vulkan_trace");
    return VkResult::VK_SUCCESS;
}

PFN_vkVoidFunction VulkanSpy::SpyOverride_vkGetInstanceProcAddr(VkInstance instance, const char* pName) {
    {{range $c := AllCommands $}}
        {{if (Macro "IsIndirected" "Command" $c "IndirectOn" "VkInstance")}}
            {{$name := Macro "CmdName" $c}}
            if(!strcmp(pName, "{{$name}}"))
              return reinterpret_cast<PFN_vkVoidFunction>(gapii::{{$name}});
        {{end}}
    {{end}}

    if (!strcmp(pName, "vkCreateInstance")) {
        return reinterpret_cast<PFN_vkVoidFunction>(gapii::vkCreateInstance);
    }
    if (!strcmp(pName, "vkEnumerateInstanceExtensionProperties")) {
        return reinterpret_cast<PFN_vkVoidFunction>(mImports.vkEnumerateInstanceExtensionProperties);
    }
    return nullptr;
  }

PFN_vkVoidFunction VulkanSpy::SpyOverride_vkGetDeviceProcAddr(VkDevice device, const char* pName) {
    {{range $c := AllCommands $}}
        {{if (Macro "IsIndirected" "Command" $c "IndirectOn" "VkDevice")}}
            {{$name := Macro "CmdName" $c}}
            if(!strcmp(pName, "{{$name}}"))
                return reinterpret_cast<PFN_vkVoidFunction>(gapii::{{$name}});
        {{end}}
    {{end}}
    // This is not strictly correct, but some applications incorrectly
    // call vkGetDeviceProcAddr, when they actually mean vkGetInstanceProcAddr.
    return SpyOverride_vkGetInstanceProcAddr(PhysicalDevices[Devices[device]->mPhysicalDevice]->mInstance, pName);
}

uint32_t VulkanSpy::SpyOverride_vkEnumerateInstanceExtensionProperties(const char *pLayerName, uint32_t *pCount, VkExtensionProperties *pProperties) {
    *pCount = 0;
    return VkResult::VK_SUCCESS;
}

uint32_t VulkanSpy::SpyOverride_vkEnumerateDeviceExtensionProperties(VkPhysicalDevice physicalDevice, const char *pLayerName, uint32_t *pCount, VkExtensionProperties *pProperties) {
    //auto next_layer_enumerate_extensions = mImports.mVkInstanceFunctions[PhysicalDevices[physicalDevice]->mInstance].vkEnumerateDeviceExtensionProperties;
    gapii::VulkanImports::PFNVKENUMERATEDEVICEEXTENSIONPROPERTIES next_layer_enumerate_extensions = NULL;
    auto phy_dev_iter = PhysicalDevices.find(physicalDevice);
    if (phy_dev_iter != PhysicalDevices.end()) {
        auto inst_func_iter = mImports.mVkInstanceFunctions.find(phy_dev_iter->second->mInstance);
        if (inst_func_iter != mImports.mVkInstanceFunctions.end()) {
            next_layer_enumerate_extensions = reinterpret_cast<gapii::VulkanImports::PFNVKENUMERATEDEVICEEXTENSIONPROPERTIES>(
                inst_func_iter->second.vkEnumerateDeviceExtensionProperties);
        }
    }

    uint32_t next_layer_count = 0;
    uint32_t next_layer_result;
    if (next_layer_enumerate_extensions) {
        next_layer_result = next_layer_enumerate_extensions(physicalDevice, pLayerName, &next_layer_count, NULL);
        if (next_layer_result != VkResult::VK_SUCCESS) {
            return next_layer_result;
        }
    }
    std::vector<VkExtensionProperties> properties(next_layer_count, VkExtensionProperties{});
    //properties.reserve(next_layer_count+1);
    if (next_layer_enumerate_extensions) {
        next_layer_result = next_layer_enumerate_extensions(physicalDevice, pLayerName, &next_layer_count, properties.data());
        if (next_layer_result != VkResult::VK_SUCCESS) {
            return next_layer_result;
        }
    }
    bool has_debug_marker_ext = false;
    for (VkExtensionProperties& ext : properties) {
        // TODO: Check the spec version and emit warning if not match.
        // TODO: refer to VK_EXT_DEBUG_MARKER_EXTENSION_NAME
        if (!strcmp(ext.mextensionName, "VK_EXT_debug_marker")) {
            has_debug_marker_ext = true;
            break;
        }
    }
    if (!has_debug_marker_ext) {
        // TODO: refer to VK_EXT_DEBUG_MARKER_EXTENSION_NAME and VK_EXT_DEBUG_MARKER_SPEC_VERSION
        char debug_marker_extension_name[] = "VK_EXT_debug_marker";
        uint32_t debug_marker_spec_version = 4;
        properties.emplace_back(VkExtensionProperties{debug_marker_extension_name, debug_marker_spec_version});
    }
    if (pProperties == NULL) {
        *pCount = properties.size();
        return VkResult::VK_SUCCESS;
    }
    uint32_t copy_count = properties.size() < *pCount ? properties.size():*pCount;
    memcpy(pProperties, properties.data(), copy_count * sizeof(VkExtensionProperties));
    if (*pCount < properties.size()) {
        return VkResult::VK_INCOMPLETE;
    }
    *pCount = properties.size();
    return VkResult::VK_SUCCESS;
}

uint32_t VulkanSpy::SpyOverride_vkCreateInstance(VkInstanceCreateInfo *pCreateInfo, VkAllocationCallbacks *pAllocator, VkInstance *pInstance) {
    VkLayerInstanceCreateInfo *layer_info = get_layer_link_info(pCreateInfo);

    // Grab the pointer to the next vkGetInstanceProcAddr in the chain.
    gapii::VulkanImports::PFNVKGETINSTANCEPROCADDR get_instance_proc_addr =
        layer_info->u.pLayerInfo->pfnNextGetInstanceProcAddr;

    // From that get the next vkCreateInstance function.
    gapii::VulkanImports::PFNVKCREATEINSTANCE create_instance = reinterpret_cast<gapii::VulkanImports::PFNVKCREATEINSTANCE>(
        get_instance_proc_addr(0, "vkCreateInstance"));

    mImports.pfn_vkCreateInstance = create_instance;
    mImports.pfn_vkEnumerateInstanceExtensionProperties \
        = reinterpret_cast<gapii::VulkanImports::PFNVKENUMERATEINSTANCEEXTENSIONPROPERTIES>(get_instance_proc_addr(0, "vkEnumerateInstanceExtensionProperties"));

    if (create_instance == NULL) {
        return VkResult::VK_ERROR_INITIALIZATION_FAILED;
    }

    // The next layer may read from layer_info,
    // so increment the pointer for it.
    layer_info->u.pLayerInfo = layer_info->u.pLayerInfo->pNext;

    // Actually call vkCreateInstance, and keep track of the result.
    uint32_t result = create_instance(pCreateInfo, pAllocator, pInstance);

    // If it failed, then we don't need to track this instance.
    if (result != VkResult::VK_SUCCESS) return result;

    mImports.vkEnumerateInstanceExtensionProperties =
        reinterpret_cast<VulkanImports::PFNVKENUMERATEINSTANCEEXTENSIONPROPERTIES>(get_instance_proc_addr(*pInstance, "vkEnumerateInstanceExtensionProperties"));
    GAPID_DEBUG("Registering instance functions for %p", *pInstance);

    // Add this instance, along with the vkGetInstanceProcAddr to our
    // map. This way when someone calls vkGetInstanceProcAddr, we can forward
    // it to the correct "next" vkGetInstanceProcAddr.
    {
        // The same instance was returned twice, this is a problem.
        auto insert_pt = mImports.mVkInstanceFunctions.insert({*pInstance, {}});
        if (!insert_pt.second) {
            // TODO(awoloszyn): Figure out if this is valid. Can an implementation return the same
            // instance for all calls to vkCreateInstance.
            return VkResult::VK_ERROR_INITIALIZATION_FAILED;
        }
        {{range $c := AllCommands $}}
            {{if (Macro "IsIndirected" "Command" $c "IndirectOn" "VkInstance")}}
                {{$name := Macro "CmdName" $c}}
                insert_pt.first->second.{{$name}} = reinterpret_cast<gapii::VulkanImports::{{Template "C++.FunctionPtrType" $c}}>(get_instance_proc_addr(*pInstance, "{{$name}}"));
            {{end}}
        {{end}}
    }
    return result;
}

void VulkanSpy::SpyOverride_vkDestroyInstance(VkInstance instance, VkAllocationCallbacks* pAllocator) {
    // First we have to find the function to chain to, then we have to
    // remove this instance from our list, then we forward the call.
    auto it = mImports.mVkInstanceFunctions.find(instance);
    gapii::VulkanImports::PFNVKDESTROYINSTANCE destroy_instance =
        it == mImports.mVkInstanceFunctions.end() ? nullptr :
        it->second.vkDestroyInstance;
    if (destroy_instance) {
      destroy_instance(instance, pAllocator);
    }
    mImports.mVkInstanceFunctions.erase(mImports.mVkInstanceFunctions.find(instance));
}

uint32_t VulkanSpy::SpyOverride_vkCreateDevice(VkPhysicalDevice physicalDevice, VkDeviceCreateInfo* pCreateInfo, VkAllocationCallbacks* pAllocator, VkDevice* pDevice) {
    VkLayerDeviceCreateInfo *layer_info = get_layer_link_info(pCreateInfo);
    // Grab the fpGetInstanceProcAddr from the layer_info. We will get
    // vkCreateDevice from this.
    // Note: we cannot use our instance_map because we do not have a
    // vkInstance here.

    gapii::VulkanImports::PFNVKGETINSTANCEPROCADDR get_instance_proc_addr =
        layer_info->u.pLayerInfo->pfnNextGetInstanceProcAddr;

    gapii::VulkanImports::PFNVKCREATEDEVICE create_device = reinterpret_cast<gapii::VulkanImports::PFNVKCREATEDEVICE>(
        get_instance_proc_addr(0, "vkCreateDevice"));

    if (!create_device) {
      return VkResult::VK_ERROR_INITIALIZATION_FAILED;
    }

    // We want to store off the next vkGetDeviceProcAddr so keep track of it now,
    // keep track of it now, before we increment the pointer.
    gapii::VulkanImports::PFNVKGETDEVICEPROCADDR get_device_proc_addr =
        layer_info->u.pLayerInfo->pfnNextGetDeviceProcAddr;

    // The next layer may read from layer_info,
    // so increment the pointer for it.
    layer_info->u.pLayerInfo = layer_info->u.pLayerInfo->pNext;

    //// Prepare the enabled extension list for the next layer's vkCreateDevice
    auto enumerate_dev_exts = reinterpret_cast<gapii::VulkanImports::PFNVKENUMERATEDEVICEEXTENSIONPROPERTIES>(
        mImports.mVkInstanceFunctions[PhysicalDevices[physicalDevice]->mInstance].vkEnumerateDeviceExtensionProperties);
    uint32_t extension_count = 0;
    uint32_t enumerate_extension_result;
    enumerate_extension_result = enumerate_dev_exts(physicalDevice, nullptr, &extension_count, nullptr);
    if (enumerate_extension_result != VkResult::VK_SUCCESS) {
      return VkResult::VK_ERROR_INITIALIZATION_FAILED;
    }
    std::vector<VkExtensionProperties> ext_properties;
    ext_properties.reserve(extension_count);
    enumerate_extension_result = enumerate_dev_exts(physicalDevice, nullptr, &extension_count, ext_properties.data());
    if (enumerate_extension_result != VkResult::VK_SUCCESS) {
      return VkResult::VK_ERROR_INITIALIZATION_FAILED;
    }
    std::vector<char*> extension_names;
    for(uint32_t i = 0; i < pCreateInfo->menabledExtensionCount; i++) {
      if (strcmp(pCreateInfo->mppEnabledExtensionNames[i], "VK_EXT_debug_marker")) {
        extension_names.push_back(pCreateInfo->mppEnabledExtensionNames[i]);
      }
    }
    pCreateInfo->mppEnabledExtensionNames = extension_names.data();
    pCreateInfo->menabledExtensionCount = extension_names.size();

    // Actually make the call to vkCreateDevice.
    uint32_t result = create_device(physicalDevice, pCreateInfo, pAllocator, pDevice);

    // If we failed, then we don't store the associated pointers.
    if (result != VkResult::VK_SUCCESS) {
      return result;
    }

    gapii::VulkanImports::PFNVKDESTROYDEVICE destroy_device = reinterpret_cast<gapii::VulkanImports::PFNVKDESTROYDEVICE>(
        get_device_proc_addr(*pDevice, "vkDestroyDevice"));

    VkDevice device = *pDevice;
    VulkanImports::VkDeviceFunctions* functions = nullptr;

    // Add this device, along with the vkGetDeviceProcAddr to our map.
    // This way when someone calls vkGetDeviceProcAddr, we can forward
    // it to the correct "next" vkGetDeviceProcAddr.
    {
        auto insert_pt = mImports.mVkDeviceFunctions.insert({*pDevice, {}});
        functions = &insert_pt.first->second;
        if (!insert_pt.second) {
            return VkResult::VK_ERROR_INITIALIZATION_FAILED;
        }
        {{range $c := AllCommands $}}
            {{if (Macro "IsIndirected" "Command" $c "IndirectOn" "VkDevice")}}
                {{$name := Macro "CmdName" $c}}
                insert_pt.first->second.{{$name}} = reinterpret_cast<gapii::VulkanImports::{{Template "C++.FunctionPtrType" $c}}>(get_device_proc_addr(*pDevice, "{{$name}}"));
            {{end}}
        {{end}}
    }

    #if COHERENT_TRACKING_ENABLED
        if (!mMemoryTracker.IsInstalled()) {
            mMemoryTracker.EnableMemoryTracker();

            VkInstance instance = PhysicalDevices[physicalDevice]->mInstance;
            auto& instance_functions = mImports.mVkInstanceFunctions[instance];
            VkPhysicalDeviceMemoryProperties props;
            instance_functions.vkGetPhysicalDeviceMemoryProperties(physicalDevice, &props);
            uint32_t coherent_bit = static_cast<uint32_t>(-1);
            for (uint32_t i = 0 ; i < props.mmemoryTypeCount; ++i) {
                if ((props.mmemoryTypes[i].mpropertyFlags & (
                    VkMemoryPropertyFlagBits::VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                    VkMemoryPropertyFlagBits::VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT)) ==
                            (VkMemoryPropertyFlagBits::VK_MEMORY_PROPERTY_HOST_COHERENT_BIT |
                             VkMemoryPropertyFlagBits::VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT)) {
                    coherent_bit = i;
                }
            }
            if (coherent_bit == static_cast<uint32_t>(-1)) {
                return VkResult::VK_ERROR_INITIALIZATION_FAILED;
            }
            uint32_t pagesize = track_memory::GetPageSize();
            VkMemoryAllocateInfo a = {
                VkStructureType::VK_STRUCTURE_TYPE_MEMORY_ALLOCATE_INFO,
                nullptr,
                pagesize,
                coherent_bit
            };
            VkDeviceMemory allocatedMemory;
            if (0 != functions->vkAllocateMemory(device, &a, nullptr, &allocatedMemory)) {
                    return VkResult::VK_ERROR_INITIALIZATION_FAILED;
            }

            void* pMemory;
            functions->vkMapMemory(device, allocatedMemory, 0, pagesize, 0, &pMemory);

            mMemoryTracker.AddTrackingRange(pMemory, pagesize);
            memset(pMemory, 32, pagesize);
            functions->vkFreeMemory(device, allocatedMemory, nullptr);
            const auto dirty_pages = mMemoryTracker.GetAndResetDirtyPagesInRange(pMemory, pagesize);
            mMemoryTracker.RemoveTrackingRange(pMemory, pagesize);
            m_coherent_memory_tracking_enabled = !dirty_pages.empty();
            if (!m_coherent_memory_tracking_enabled) {
                GAPID_WARNING("Memory tracker requested, but does not work on this system");
                GAPID_WARNING("Falling back to non-tracked memory");
            }
        }
    #endif

    return result;
}

uint32_t VulkanSpy::SpyOverride_vkCreateBuffer(
        VkDevice                     device,
        VkBufferCreateInfo*          pCreateInfo,
        VkAllocationCallbacks*       pAllocator,
        VkBuffer*                    pBuffer) {
    if (is_suspended()) {
        VkBufferCreateInfo override_create_info = *pCreateInfo;
        override_create_info.musage |= VkBufferUsageFlagBits::VK_BUFFER_USAGE_TRANSFER_SRC_BIT;
        return  mImports.mVkDeviceFunctions[device].vkCreateBuffer(device, &override_create_info, pAllocator, pBuffer);
    } else {
        return  mImports.mVkDeviceFunctions[device].vkCreateBuffer(device, pCreateInfo, pAllocator, pBuffer);
    }
}

uint32_t VulkanSpy::SpyOverride_createImageAndCacheMemoryRequirements(
    VkDevice device, VkImageCreateInfo* pCreateInfo,
    VkAllocationCallbacks* pAllocator, VkImage* pImage,
    VkMemoryRequirements* pMemoryRequirements) {
  uint32_t result = VkResult::VK_SUCCESS;
  VkImageCreateInfo override_create_info = *pCreateInfo;
  override_create_info.musage |=
      VkImageUsageFlagBits::VK_IMAGE_USAGE_TRANSFER_SRC_BIT;
  result = mImports.mVkDeviceFunctions[device].vkCreateImage(
      device, &override_create_info, pAllocator, pImage);
  if (result != VkResult::VK_SUCCESS) {
    return result;
  }

  if (pMemoryRequirements != nullptr) {
    mImports.mVkDeviceFunctions[device].vkGetImageMemoryRequirements(
        device, *pImage, pMemoryRequirements);
  }
  return result;
}

void VulkanSpy::SpyOverride_cacheImageSparseMemoryRequirements(
    VkDevice device, VkImage image, uint32_t count,
    VkSparseImageMemoryRequirements* pSparseMemoryRequirements) {}

uint32_t VulkanSpy::SpyOverride_vkCreateImage(VkDevice device,
                                              VkImageCreateInfo* pCreateInfo,
                                              VkAllocationCallbacks* pAllocator,
                                              VkImage* pImage) {
  if (is_suspended() || is_observing()) {
    VkMemoryRequirements memReq;
    uint32_t result = gapii::createImageAndCacheMemoryRequirements(
        device, pCreateInfo, pAllocator, pImage, &memReq);
    if (result != VkResult::VK_SUCCESS) {
      return result;
    }
    // sparse memory requirement is only necessary if the image is created with
    // VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT.
    if ((pCreateInfo->mflags &
         VkImageCreateFlagBits::VK_IMAGE_CREATE_SPARSE_RESIDENCY_BIT) != 0) {
      uint32_t sparseMemReqCount = 0;
      mImports.mVkDeviceFunctions[device].vkGetImageSparseMemoryRequirements(
          device, *pImage, &sparseMemReqCount, nullptr);
      std::vector<VkSparseImageMemoryRequirements> sparseMemReqs(
          sparseMemReqCount, VkSparseImageMemoryRequirements{});
      mImports.mVkDeviceFunctions[device].vkGetImageSparseMemoryRequirements(
          device, *pImage, &sparseMemReqCount, sparseMemReqs.data());
      gapii::cacheImageSparseMemoryRequirements(
          device, *pImage, sparseMemReqCount, sparseMemReqs.data());
    }
    return result;
  }
  return mImports.mVkDeviceFunctions[device].vkCreateImage(device, pCreateInfo,
                                                           pAllocator, pImage);
}

uint32_t VulkanSpy::SpyOverride_vkCreateSwapchainKHR(
        VkDevice                         device,
        VkSwapchainCreateInfoKHR*           pCreateInfo,
        VkAllocationCallbacks*           pAllocator,
        VkSwapchainKHR*                  pImage) {
    if (is_observing()) {
        VkSwapchainCreateInfoKHR override_create_info = *pCreateInfo;
        override_create_info.mimageUsage |= VkImageUsageFlagBits::VK_IMAGE_USAGE_TRANSFER_SRC_BIT;
        return  mImports.mVkDeviceFunctions[device].vkCreateSwapchainKHR(device, &override_create_info, pAllocator, pImage);
    } else {
        return  mImports.mVkDeviceFunctions[device].vkCreateSwapchainKHR(device, pCreateInfo, pAllocator, pImage);
    }
}

void VulkanSpy::SpyOverride_vkDestroyDevice(VkDevice device, VkAllocationCallbacks* pAllocator) {
    // First we have to find the function to chain to, then we have to
    // remove this instance from our list, then we forward the call.
    auto it = mImports.mVkDeviceFunctions.find(device);
    gapii::VulkanImports::PFNVKDESTROYDEVICE destroy_device =
        it == mImports.mVkDeviceFunctions.end()
            ? nullptr
            : it->second.vkDestroyDevice;
    if (destroy_device) {
        destroy_device(device, pAllocator);
    }
    mImports.mVkDeviceFunctions.erase(mImports.mVkDeviceFunctions.find(device));
}

bool VulkanSpy::hasDynamicProperty(CallObserver* observer, VkPipelineDynamicStateCreateInfo* info, uint32_t state) {
    if (!info) { return false; }
    for (size_t i = 0; i < info->mdynamicStateCount; ++i) {
        if (info->mpDynamicStates[i] == state) {
            return true;
        }
    }
    return false;
}

// Externs not implemented in GAPII.
void VulkanSpy::mapMemory(CallObserver*, void**, Slice<uint8_t>) {}
void VulkanSpy::unmapMemory(CallObserver*, Slice<uint8_t>) {}

void VulkanSpy::execPendingCommands(CallObserver* observer, VkQueue queue) {
  LastBoundQueue = Queues[queue];
  U32ToCommandReference newPendingCommands;

  for (uint32_t i = 0; i < LastBoundQueue->mPendingCommands.size(); ++i) {
    auto& cmd = LastBoundQueue->mPendingCommands[i];
    if (LastBoundQueue->mPendingEvents.size() != 0) {
      newPendingCommands[static_cast<uint32_t>(newPendingCommands.size())]
          = cmd;
    } else {
      if (cmd.mSemaphoreUpdate == SemaphoreUpdate::Signal) {
        Semaphores[cmd.mSemaphore]->mSignaled = true;
      } else if (cmd.mSemaphoreUpdate == SemaphoreUpdate::Unsignal) {
        Semaphores[cmd.mSemaphore]->mSignaled = false;
      }
      if (cmd.mSparseBinds != nullptr) {
        for (const auto& bb : cmd.mSparseBinds->mBufferBinds) {
          VkBuffer buf = bb.first;
          if (mBufferSparseBindings.find(buf) == mBufferSparseBindings.end()) {
            mBufferSparseBindings[buf] = SparseBindingList();
          }
          for (const auto& b : bb.second->mSparseMemoryBinds) {
            mBufferSparseBindings[buf].replace(
                VulkanSpy::SparseBindingInterval(b.second));
          }
          for (uint32_t i = 0; i < Buffers[buf]->mSparseMemoryBindings.size() ||
                               i < mBufferSparseBindings[buf].count();
               i++) {
            if (i >= mBufferSparseBindings[buf].count()) {
              Buffers[buf]->mSparseMemoryBindings.erase(i);
            }
            Buffers[buf]->mSparseMemoryBindings[i] =
                mBufferSparseBindings[buf][i].sparseMemoryBind();
          }
        }
        for (const auto& ob : cmd.mSparseBinds->mOpaqueImageBinds) {
          VkImage img = ob.first;
          if (mOpaqueImageSparseBindings.find(img) ==
              mOpaqueImageSparseBindings.end()) {
            mOpaqueImageSparseBindings[img] = SparseBindingList();
          }
          for (const auto& b : ob.second->mSparseMemoryBinds) {
            mOpaqueImageSparseBindings[img].replace(
                VulkanSpy::SparseBindingInterval(b.second));
          }
          for (uint32_t i = 0;
               i < Images[img]->mOpaqueSparseMemoryBindings.size() ||
               i < mOpaqueImageSparseBindings[img].count();
               i++) {
            if (i >= mOpaqueImageSparseBindings[img].count()) {
              Images[img]->mOpaqueSparseMemoryBindings.erase(i);
            }
            Images[img]->mOpaqueSparseMemoryBindings[i] =
                mOpaqueImageSparseBindings[img][i].sparseMemoryBind();
          }
        }
      }
      if (cmd.mBuffer == 0) {
          continue;
      }
      CommandBuffers[cmd.mBuffer]->commands[cmd.mCommandIndex](observer);
      if (LastBoundQueue->mPendingEvents.size() != 0) {
        // Make sure the vkCmdWaitEvents is also added to the pending list
        newPendingCommands[static_cast<uint32_t>(newPendingCommands.size())] = cmd;
      }
    }
  }
  LastBoundQueue->mPendingCommands = std::move(newPendingCommands);
}

void VulkanSpy::resetCmd(CallObserver* observer, VkCommandBuffer cmdBuf) {
    auto& buffer = CommandBuffers[cmdBuf];
    buffer->mCommandReferences = U32ToCommandReference();
    buffer->commands.clear();
}

void VulkanSpy::trackMappedCoherentMemory(CallObserver*, uint64_t start, size_val size) {
  // If the tracing not started yet, do not track the coherent memory
  if (is_suspended()) {
      return;
  }
#if COHERENT_TRACKING_ENABLED
    if (m_coherent_memory_tracking_enabled) {
        void* start_addr = reinterpret_cast<void*>(start);
        mMemoryTracker.AddTrackingRange(start_addr, size);
    }
#endif // COHERENT_TRACKING_ENABLED
}


void VulkanSpy::readMappedCoherentMemory(CallObserver *observer, VkDeviceMemory memory, uint64_t offset_in_mapped, size_val readSize) {
    auto &memory_object = this->DeviceMemories[memory];
    const auto mapped_size = memory_object->mMappedSize;
    const auto mapped_location = (uint64_t)(memory_object->mMappedLocation);
    void *offset_addr = (void *)(offset_in_mapped + mapped_location);
#if COHERENT_TRACKING_ENABLED
    if (m_coherent_memory_tracking_enabled) {
        const size_val page_size = mMemoryTracker.page_size();
        // Get the valid mapped range
        const auto dirty_pages = mMemoryTracker.GetAndResetDirtyPagesInRange(offset_addr, readSize);
        for (const void *p : dirty_pages) {
            uint64_t page_start = (uint64_t)(p);
            uint64_t page_end = page_start + page_size;
            observer->read(slice((uint8_t *)page_start, 0ULL, page_size));
        }
        return;
    }
#endif // COHERENT_TRACKING_ENABLED
    observer->read(slice((uint8_t *)offset_addr, 0ULL, readSize));
}

void VulkanSpy::untrackMappedCoherentMemory(CallObserver*, uint64_t start, size_val size) {
#if COHERENT_TRACKING_ENABLED
    if (m_coherent_memory_tracking_enabled) {
        void* start_addr = reinterpret_cast<void*>(start);
        mMemoryTracker.RemoveTrackingRange(start_addr, size);
    }
#endif // COHERENT_TRACKING_ENABLED
}

uint32_t VulkanSpy::SpyOverride_vkAllocateMemory(VkDevice device, VkMemoryAllocateInfo* pAllocateInfo, VkAllocationCallbacks* pAllocator, VkDeviceMemory* pMemory) {
    uint32_t r = mImports.mVkDeviceFunctions[device].vkAllocateMemory(device, pAllocateInfo, pAllocator, pMemory);
    std::shared_ptr<PhysicalDeviceObject> l_physical_device = PhysicalDevices[Devices[device]->mPhysicalDevice];
    if (0 != (l_physical_device->mMemoryProperties.mmemoryTypes[pAllocateInfo->mmemoryTypeIndex].mpropertyFlags &
        ((uint32_t)(VkMemoryPropertyFlagBits::VK_MEMORY_PROPERTY_HOST_COHERENT_BIT)))) {
        // This is host-coherent memory. Some drivers actually allocate these pages on-demand.
        // This forces all of the pages to be created.
        // This is needed as our coherent memory tracker relies on page-faults which interferes with the
        // on-demand allocation.
        char* memory;
        mImports.mVkDeviceFunctions[device].vkMapMemory(device, *pMemory, 0, pAllocateInfo->mallocationSize, 0, reinterpret_cast<void**>(&memory));
        memset(memory, 0x00, pAllocateInfo->mallocationSize);
        mImports.mVkDeviceFunctions[device].vkUnmapMemory(device, *pMemory);
    }
    return r;
}

void VulkanSpy::SpyOverride_prefetchPhysicalDeviceProperties(
    VkInstance instance, VkPhysicalDevice physicalDevice,
    VkPhysicalDeviceProperties* pProperties) {
  return mImports.mVkInstanceFunctions[instance].vkGetPhysicalDeviceProperties(
      physicalDevice, pProperties);
}

void VulkanSpy::SpyOverride_prefetchPhysicalDeviceQueueFamilyProperties(
    VkInstance instance, VkPhysicalDevice physicalDevice,
    uint32_t* pQueueFamilyPropertyCount,
    VkQueueFamilyProperties* pQueueFamilyProperties) {
  return mImports.mVkInstanceFunctions[instance]
      .vkGetPhysicalDeviceQueueFamilyProperties(
          physicalDevice, pQueueFamilyPropertyCount, pQueueFamilyProperties);
}

uint32_t VulkanSpy::SpyOverride_vkEnumeratePhysicalDevices(
VkInstance instance, uint32_t* pPhysicalDeviceCount,
VkPhysicalDevice* pPhysicalDevices) {
    uint32_t fill_count = pPhysicalDevices? *pPhysicalDeviceCount : 0;
    uint32_t r = mImports.mVkInstanceFunctions[instance].vkEnumeratePhysicalDevices(instance, pPhysicalDeviceCount, pPhysicalDevices);
    if (fill_count > *pPhysicalDeviceCount) {
        fill_count = *pPhysicalDeviceCount;
    }
    for (size_t i = 0; i < fill_count; ++i) {
        VkPhysicalDeviceProperties properties;
        gapii::prefetchPhysicalDeviceProperties(instance, pPhysicalDevices[i],
                                                &properties);
        uint32_t queue_family_prop_count = 0;
        gapii::prefetchPhysicalDeviceQueueFamilyProperties(
            instance, pPhysicalDevices[i], &queue_family_prop_count, nullptr);
        std::vector<VkQueueFamilyProperties> queue_family_properties(
            queue_family_prop_count, VkQueueFamilyProperties{});
        gapii::prefetchPhysicalDeviceQueueFamilyProperties(
            instance, pPhysicalDevices[i], &queue_family_prop_count,
            queue_family_properties.data());
    }
    return r;
}

uint32_t VulkanSpy::numberOfPNext(CallObserver* observer, void* pNext) {
  uint32_t counter = 0;
  while (pNext) {
    counter++;
    pNext = reinterpret_cast<void*>(reinterpret_cast<uintptr_t*>(pNext)[1]);
  }
  return counter;
}

void VulkanSpy::pushDebugMarker(CallObserver*, std::string) {}
void VulkanSpy::popDebugMarker(CallObserver*) {}
void VulkanSpy::pushRenderPassMarker(CallObserver*, VkRenderPass) {}
void VulkanSpy::popRenderPassMarker(CallObserver*) {}
void VulkanSpy::popAndPushMarkerForNextSubpass(CallObserver*, uint32_t) {}
}
{{end}}
