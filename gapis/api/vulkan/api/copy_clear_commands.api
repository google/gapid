// Copyright (C) 2018 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//      http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Based off of the original vulkan.h header file which has the following
// license.

// Copyright (c) 2015 The Khronos Group Inc.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and/or associated documentation files (the
// "Materials"), to deal in the Materials without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Materials, and to
// permit persons to whom the Materials are furnished to do so, subject to
// the following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Materials.
//
// THE MATERIALS ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
// EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
// IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
// CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
// TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
// MATERIALS OR THE USE OR OTHER DEALINGS IN THE MATERIALS.

@internal class vkCmdCopyBufferArgs {
  VkBuffer                SrcBuffer  ,
  VkBuffer                DstBuffer  ,
  map!(u32, VkBufferCopy) CopyRegions
}

sub void dovkCmdCopyBuffer(ref!vkCmdCopyBufferArgs buffer) {
  if !(buffer.SrcBuffer in Buffers) { vkErrorInvalidBuffer(buffer.SrcBuffer) }
  if !(buffer.DstBuffer in Buffers) { vkErrorInvalidBuffer(buffer.DstBuffer) }
  sourceBuffer := Buffers[buffer.SrcBuffer]
  destBuffer := Buffers[buffer.DstBuffer]
  for _ , _ , region in buffer.CopyRegions {
    readCoherentMemoryInBuffer(sourceBuffer)
    copyBufferToBuffer(destBuffer, region.dstOffset, sourceBuffer, region.srcOffset, region.size)
  }
}

@internal class OpaqueResourceMemoryBoundPiece {
  VkDeviceSize           ResourceOffset
  VkDeviceSize           Size
  ref!DeviceMemoryObject DeviceMemory
  VkDeviceSize           MemoryOffset
}

@internal class OpaqueResourceMemoryBoundPieceReturnMap {
  map!(VkDeviceSize, OpaqueResourceMemoryBoundPiece) Map
}

// getBufferBoundMemoryPiecesInRange returns all the memory-bound ranges that
// overlaps with the buffer range given with offset and size. The returned
// memory-bound ranges are guaranteed to be valid to access, and so as a whole
// may be a subset of the given range. For each returned memory-bound range, it
// is guaranteed to be a subset of the buffer's total resource range, the
// corresponding sparse memory bind (if any), and the underlying device memory
// allocation range.
sub map!(VkDeviceSize, OpaqueResourceMemoryBoundPiece) getBufferBoundMemoryPiecesInRange(
    ref!BufferObject buf, VkDeviceSize offset, VkDeviceSize size) {
  ret_val := OpaqueResourceMemoryBoundPieceReturnMap()

  noOverflowEnd := switch (size == 0xFFFFFFFFFFFFFFFF) ||
  ((size + offset) < size) {
    case true:
      // size value is VK_WHOLE_SIZE or can overflow
      buf.Info.Size
    case false:
      size + offset
  }
  end := min!VkDeviceSize(noOverflowEnd, buf.Info.Size)
  if offset < end {
    if buf.Memory != null {
      memOffset := offset + buf.MemoryOffset
      memEnd := min!VkDeviceSize(end + buf.MemoryOffset, buf.Memory.AllocationSize)
      if memOffset < memEnd {
        ret_val.Map[offset] = OpaqueResourceMemoryBoundPiece(
          ResourceOffset: offset,
          Size:           memEnd - memOffset,
          DeviceMemory:   buf.Memory,
          MemoryOffset:   memOffset,
        )
      }

    } else {
      // sparsely bound
      for _ , blkOffset , bind in buf.SparseMemoryBindings {
        resStart := max!VkDeviceSize(as!VkDeviceSize(blkOffset), offset)
        resEnd := min!VkDeviceSize(as!VkDeviceSize(blkOffset) + bind.size, end)
        if (resStart < resEnd) && (DeviceMemories[bind.memory] != null) {
          mem := DeviceMemories[bind.memory]
          memStart := (resStart - bind.resourceOffset) + bind.memoryOffset
          memEnd := min!VkDeviceSize(((resEnd - bind.resourceOffset) + bind.memoryOffset), mem.AllocationSize)
          if memStart < memEnd {
            ret_val.Map[resStart] = OpaqueResourceMemoryBoundPiece(
              ResourceOffset: resStart,
              Size:           memEnd - memStart,
              DeviceMemory:   mem,
              MemoryOffset:   memStart,
            )
          }
        }
      }
    }
  }
  return ret_val.Map
}

@spy_disabled
sub void copyBufferToBuffer(ref!BufferObject dstBuf, VkDeviceSize dstOffset, ref!BufferObject srcBuf, VkDeviceSize srcOffset, VkDeviceSize size) {
  if (dstBuf.Memory != null) && (srcBuf.Memory != null) {
    // No sparse binding in either dst and src
    srcMemOffset := srcBuf.MemoryOffset + srcOffset
    dstMemOffset := dstBuf.MemoryOffset + dstOffset
    srcMemEnd := min!VkDeviceSize(srcMemOffset + size, srcBuf.Memory.AllocationSize)
    dstMemEnd := min!VkDeviceSize(dstMemOffset + size, dstBuf.Memory.AllocationSize)
    if (srcMemOffset < srcMemEnd) && (dstMemOffset < dstMemEnd) {
      copy(dstBuf.Memory.Data[dstMemOffset:dstMemEnd], srcBuf.Memory.Data[srcMemOffset:srcMemEnd])
    }

  } else if (dstBuf.Memory != null) && (len(srcBuf.SparseMemoryBindings) != 0) {
      // Sparse binding in src
      srcMemPieces := getBufferBoundMemoryPiecesInRange(srcBuf, srcOffset, size)
      for _ , _ , smp in srcMemPieces {
        srcMemOffset := as!u64(smp.MemoryOffset)
        dstMemOffset := as!u64((smp.ResourceOffset - srcOffset) + dstOffset)
        if dstMemOffset < as!u64(dstBuf.Memory.AllocationSize) {
          memSize := min!u64(as!u64(smp.Size), as!u64(dstBuf.Memory.AllocationSize) - dstMemOffset)
          copy(dstBuf.Memory.Data[dstMemOffset:dstMemOffset + memSize],
            srcBuf.Memory.Data[srcMemOffset:srcMemOffset + memSize])
        }
      }

    } else if (len(dstBuf.SparseMemoryBindings) != 0) && (srcBuf.Memory != null) {
        // Sparse binding in dst
        dstMemPieces := getBufferBoundMemoryPiecesInRange(dstBuf, dstOffset, size)
        for _ , _ , dmp in dstMemPieces {
          dstMemOffset := dmp.MemoryOffset
          srcMemOffset := (dmp.ResourceOffset - dstOffset) + srcOffset
          if srcMemOffset < as!VkDeviceSize(srcBuf.Memory.AllocationSize) {
            memSize := min!VkDeviceSize(dmp.Size, as!VkDeviceSize(srcBuf.Memory.AllocationSize) - srcMemOffset)
            copy(dstBuf.Memory.Data[dstMemOffset:dstMemOffset + memSize],
              srcBuf.Memory.Data[srcMemOffset:srcMemOffset + memSize])
          }
        }

      } else if (len(dstBuf.SparseMemoryBindings) != 0) && (len(srcBuf.SparseMemoryBindings) != 0) {
          // Sparse binding in src and dst
          dstMemPieces := getBufferBoundMemoryPiecesInRange(dstBuf, dstOffset, size)
          for _ , _ , dmp in dstMemPieces {
            tmpSrcOffset := (dmp.ResourceOffset - dstOffset) + srcOffset
            tmpSize := dmp.Size
            srcMemPieces := getBufferBoundMemoryPiecesInRange(srcBuf, tmpSrcOffset, tmpSize)
            for _ , _ , smp in srcMemPieces {
              srcMemOffset := as!u64(smp.MemoryOffset)
              dstMemOffset := as!u64((smp.ResourceOffset - tmpSrcOffset) + dmp.ResourceOffset)
              memSize := as!u64(smp.Size)
              copy(dstBuf.Memory.Data[dstMemOffset:dstMemOffset + memSize],
                srcBuf.Memory.Data[srcMemOffset:srcMemOffset + memSize])
            }
          }
        }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdCopyBuffer(
    VkCommandBuffer     commandBuffer,
    VkBuffer            srcBuffer,
    VkBuffer            dstBuffer,
    u32                 regionCount,
    const VkBufferCopy* pRegions) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(srcBuffer in Buffers) {
      vkErrorInvalidBuffer(srcBuffer)
    } else {
      if !(dstBuffer in Buffers) {
        vkErrorInvalidBuffer(dstBuffer)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]

        args := new!vkCmdCopyBufferArgs(
          SrcBuffer:  srcBuffer,
          DstBuffer:  dstBuffer
        )
        regions := pRegions[0:regionCount]
        for i in (0 .. regionCount) {
          args.CopyRegions[i] = regions[i]
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdCopyBuffer))
        cmdBuf.BufferCommands.vkCmdCopyBuffer[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdCopyBuffer, mapPos)
      }
    }
  }
}

@internal
class vkCmdCopyImageArgs {
  VkImage                SrcImage
  VkImageLayout          SrcImageLayout
  VkImage                DstImage
  VkImageLayout          DstImageLayout
  map!(u32, VkImageCopy) Regions
}

@spy_disabled
sub void trackVkCmdCopyImage(ref!vkCmdCopyImageArgs args) {
  srcImageObject := Images[args.SrcImage]
  dstImageObject := Images[args.DstImage]

  srcFormat := srcImageObject.Info.Format

  dstFormat := dstImageObject.Info.Format

  n := len(args.Regions)
  for r in (0 .. n) {
    // TODO: Support KHR_maintenance1 extension, support copying from a 2D array
    // image to slices of a 3D image and vice versa.
    region := args.Regions[as!u32(r)]
    srcBaseLayer := region.srcSubresource.baseArrayLayer
    dstBaseLayer := region.srcSubresource.baseArrayLayer
    srcMipLevel := region.srcSubresource.mipLevel
    dstMipLevel := region.dstSubresource.mipLevel

    numPlanes := numberOfPlanes(srcImageObject.Info.Format)
    numDstPlanes := numberOfPlanes(dstImageObject.Info.Format)
    // From VU: srcSubresource.aspectMask must == dstSubresource.aspectMask unless
    // we are multiplanar, in which case there must be only 1 bit set.
    if (numPlanes == 0) && (numDstPlanes == 0) {
      if region.srcSubresource.aspectMask != region.dstSubresource.aspectMask {
        vkErrorInvalidImageAspect(srcImageObject.VulkanHandle, as!VkImageAspectFlagBits(region.srcSubresource.aspectMask))
        vkErrorInvalidImageAspect(dstImageObject.VulkanHandle, as!VkImageAspectFlagBits(region.dstSubresource.aspectMask))
      }
    }

    for _ , _ , aspectBit in unpackImageAspectFlags(srcImageObject, region.srcSubresource.aspectMask) {
      dstAspect := switch ((numDstPlanes != 0) || (numPlanes != 0)) {
        case true: {
          as!VkImageAspectFlagBits(region.dstSubresource.aspectMask)
        }
        case false: {
          aspectBit
        }
      }
      srcAspectTexelBlockSize := getElementAndTexelBlockSizeForAspect(srcFormat, aspectBit)
      srcElementSize := srcAspectTexelBlockSize.ElementSize

      srcBlockWidth := as!u64(srcAspectTexelBlockSize.TexelBlockSize.Width)
      srcBlockHeight := as!u64(srcAspectTexelBlockSize.TexelBlockSize.Height)

      dstAspectTexelBlockSize := getElementAndTexelBlockSizeForAspect(dstFormat, dstAspect)
      dstElementSize := dstAspectTexelBlockSize.ElementSize

      dstBlockWidth := as!u64(dstAspectTexelBlockSize.TexelBlockSize.Width)
      dstBlockHeight := as!u64(dstAspectTexelBlockSize.TexelBlockSize.Height)

      srcXStartInBlocks := as!u64(as!u64(region.srcOffset.x) / srcBlockWidth)
      srcYStartInBlocks := as!u64(as!u64(region.srcOffset.y) / srcBlockHeight)
      srcZStart := as!u64(region.srcOffset.z)
      dstXStartInBlocks := as!u64(as!u64(region.dstOffset.x) / dstBlockWidth)
      dstYStartInBlocks := as!u64(as!u64(region.dstOffset.y) / dstBlockHeight)
      dstZStart := as!u64(region.dstOffset.z)

      extentXInBlocks := roundUpTo(region.extent.width, as!u32(srcBlockWidth))
      extentYInBlocks := roundUpTo(region.extent.height, as!u32(srcBlockHeight))
      extentZ := region.extent.depth

      srcImageLevelWidthInBlocks := as!u64(roundUpTo(getMipSize(srcImageObject.Info.Extent.width, srcMipLevel), as!u32(srcBlockWidth)))
      srcImageLevelHeightInBlocks := as!u64(roundUpTo(getMipSize(srcImageObject.Info.Extent.height, srcMipLevel), as!u32(srcBlockHeight)))
      dstImageLevelWidthInBlocks := as!u64(roundUpTo(getMipSize(dstImageObject.Info.Extent.width, dstMipLevel), as!u32(dstBlockWidth)))
      dstImageLevelHeightInBlocks := as!u64(roundUpTo(getMipSize(dstImageObject.Info.Extent.height, dstMipLevel), as!u32(dstBlockHeight)))

      minLayerCount := min!u32(region.srcSubresource.layerCount, region.dstSubresource.layerCount)
      maxLayerCount := max!u32(region.srcSubresource.layerCount, region.dstSubresource.layerCount)

      layerCount := switch srcImageObject.Info.ImageType == dstImageObject.Info.ImageType {
        case true:
          // Same type of image
          minLayerCount
        case false:
          // Must be a 3D image <-> 2D array image copy, use the 2D array image's layer count
          maxLayerCount
      }

      for l in (0 .. layerCount) {
        srcImageLevel := switch srcImageObject.Info.ImageType {
          case VK_IMAGE_TYPE_3D:
            srcImageObject.Aspects[aspectBit].Layers[as!u32(0)].Levels[srcMipLevel]
          default:
            srcImageObject.Aspects[aspectBit].Layers[srcBaseLayer + l].Levels[srcMipLevel]
        }

        dstImageLevel := switch dstImageObject.Info.ImageType {
          case VK_IMAGE_TYPE_3D:
            dstImageObject.Aspects[dstAspect].Layers[as!u32(0)].Levels[dstMipLevel]
          default:
            dstImageObject.Aspects[dstAspect].Layers[dstBaseLayer + l].Levels[dstMipLevel]
        }

        for z in (0 .. extentZ) {
          for y in (0 .. extentYInBlocks) {
            copySize := as!u64(extentXInBlocks) * as!u64(srcElementSize)
            dstY := dstYStartInBlocks + as!u64(y)
            dstZ := switch dstImageObject.Info.ImageType {
              case VK_IMAGE_TYPE_3D:
                dstZStart + as!u64(z)
              default:
                dstZStart
            }
            srcY := srcYStartInBlocks + as!u64(y)
            srcZ := switch srcImageObject.Info.ImageType {
              case VK_IMAGE_TYPE_3D:
                srcZStart + as!u64(z)
              default:
                srcZStart
            }
            dstStart := ((((dstZ * dstImageLevelHeightInBlocks) + dstY) * dstImageLevelWidthInBlocks) + dstXStartInBlocks) * as!u64(dstElementSize)
            srcStart := ((((srcZ * srcImageLevelHeightInBlocks) + srcY) * srcImageLevelWidthInBlocks) + srcXStartInBlocks) * as!u64(srcElementSize)
            copy(dstImageLevel.Data[dstStart:dstStart + copySize], srcImageLevel.Data[srcStart:srcStart + copySize])
          }
        }
      }
    }
  }
}

sub void dovkCmdCopyImage(ref!vkCmdCopyImageArgs args) {
  if !(args.SrcImage in Images) { vkErrorInvalidImage(args.SrcImage) }
  if !(args.DstImage in Images) { vkErrorInvalidImage(args.DstImage) }
  srcImageObject := Images[args.SrcImage]

  // The following read on coherent memory of the source image does not affect the data in imageLevel.Data, as they are different memory spaces.
  // But such a read is necessary if the backing memory of the source image is coherent, as we need the read observations on all memory changes
  // in order to replay correctly. However, as the UI's texture data comes from imageLevel.Data, just using the following call will not bring
  // the changes in coherent memory to the UI's texture view.
  readCoherentMemoryInImage(srcImageObject)
  trackVkCmdCopyImage(args)
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdCopyImage(
    VkCommandBuffer    commandBuffer,
    VkImage            srcImage,
    VkImageLayout      srcImageLayout,
    VkImage            dstImage,
    VkImageLayout      dstImageLayout,
    u32                regionCount,
    const VkImageCopy* pRegions) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(srcImage in Images) {
      vkErrorInvalidImage(srcImage)
    } else {
      if !(dstImage in Images) {
        vkErrorInvalidImage(dstImage)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]
        args := new!vkCmdCopyImageArgs(
          SrcImage:        srcImage,
          SrcImageLayout:  srcImageLayout,
          DstImage:        dstImage,
          DstImageLayout:  dstImageLayout
        )
        regions := pRegions[0:regionCount]
        for i in (0 .. regionCount) {
          args.Regions[i] = regions[i]
        }
        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdCopyImage))
        cmdBuf.BufferCommands.vkCmdCopyImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdCopyImage, mapPos)
      }
    }
  }
}

@internal
class vkCmdBlitImageArgs {
  VkImage                SrcImage
  VkImageLayout          SrcImageLayout
  VkImage                DstImage
  VkImageLayout          DstImageLayout
  map!(u32, VkImageBlit) Regions
  VkFilter               Filter
}

@spy_disabled
sub void trackVkCmdBlitImage(ref!vkCmdBlitImageArgs args) {
  srcImageObject := Images[args.SrcImage]
  dstImageObject := Images[args.DstImage]

  srcFormat := srcImageObject.Info.Format
  srcElementAndTexelBlockSize := getElementAndTexelBlockSize(srcFormat)
  srcDepthElementSize := getDepthElementSize(srcFormat, false)
  dstFormat := dstImageObject.Info.Format
  dstElementAndTexelBlockSize := getElementAndTexelBlockSize(dstFormat)
  dstDepthElementSize := getDepthElementSize(dstFormat, false)
  n := len(args.Regions)
  for r in (0 .. n) {
    // TODO: (qining) Handle the apsect mask
    region := args.Regions[as!u32(r)]
    srcBaseLayer := region.srcSubresource.baseArrayLayer
    dstBaseLayer := region.srcSubresource.baseArrayLayer
    srcMipLevel := region.srcSubresource.mipLevel
    dstMipLevel := region.dstSubresource.mipLevel

    // TODO: Handle multi-planar image correctly. The dst image aspect must
    // ether match or contains only COLOR_BIT with a compatible format.
    for _ , _ , aspectBit in unpackImageAspectFlags(srcImageObject, region.srcSubresource.aspectMask) {
      //Multiplanar images must not be used in BlitImage
      srcElementSize := switch (aspectBit) {
        case VK_IMAGE_ASPECT_COLOR_BIT:
          as!u64(srcElementAndTexelBlockSize.ElementSize)
        case VK_IMAGE_ASPECT_DEPTH_BIT:
          as!u64(srcDepthElementSize)
        case VK_IMAGE_ASPECT_STENCIL_BIT:
          as!u64(1)
      }
      srcBlockWidth := as!u64(srcElementAndTexelBlockSize.TexelBlockSize.Width)
      srcBlockHeight := as!u64(srcElementAndTexelBlockSize.TexelBlockSize.Height)

      dstElementSize := switch (aspectBit) {
        case VK_IMAGE_ASPECT_COLOR_BIT:
          as!u64(dstElementAndTexelBlockSize.ElementSize)
        case VK_IMAGE_ASPECT_DEPTH_BIT:
          as!u64(dstDepthElementSize)
        case VK_IMAGE_ASPECT_STENCIL_BIT:
          as!u64(1)
      }
      dstBlockWidth := as!u64(dstElementAndTexelBlockSize.TexelBlockSize.Width)
      dstBlockHeight := as!u64(dstElementAndTexelBlockSize.TexelBlockSize.Height)

      srcOffsetX := min!s32(region.srcOffsets[0].x, region.srcOffsets[1].x)
      srcExtentX := max!s32(region.srcOffsets[0].x, region.srcOffsets[1].x) - srcOffsetX
      srcOffsetY := min!s32(region.srcOffsets[0].y, region.srcOffsets[1].y)
      srcExtentY := max!s32(region.srcOffsets[0].y, region.srcOffsets[1].y) - srcOffsetY
      srcOffsetZ := min!s32(region.srcOffsets[0].z, region.srcOffsets[1].z)
      srcExtentZ := max!s32(region.srcOffsets[0].z, region.srcOffsets[1].z) - srcOffsetZ

      dstOffsetX := min!s32(region.dstOffsets[0].x, region.dstOffsets[1].x)
      dstExtentX := max!s32(region.dstOffsets[0].x, region.dstOffsets[1].x) - dstOffsetX
      dstOffsetY := min!s32(region.dstOffsets[0].y, region.dstOffsets[1].y)
      dstExtentY := max!s32(region.dstOffsets[0].y, region.dstOffsets[1].y) - dstOffsetY
      dstOffsetZ := min!s32(region.dstOffsets[0].z, region.dstOffsets[1].z)
      dstExtentZ := max!s32(region.dstOffsets[0].z, region.dstOffsets[1].z) - dstOffsetZ

      srcXStartInBlocks := as!u64(srcOffsetX) / srcBlockWidth
      srcYStartInBlocks := as!u64(srcOffsetY) / srcBlockHeight
      srcZStart := as!u64(srcOffsetZ)
      dstXStartInBlocks := as!u64(dstOffsetX) / dstBlockWidth
      dstYStartInBlocks := as!u64(dstOffsetY) / dstBlockHeight
      dstZStart := as!u64(dstOffsetZ)

      srcExtentXInBlocks := roundUpTo(as!u32(srcExtentX), as!u32(srcBlockWidth))
      srcExtentYInBlocks := roundUpTo(as!u32(srcExtentY), as!u32(srcBlockHeight))
      dstExtentXInBlocks := roundUpTo(as!u32(dstExtentX), as!u32(dstBlockWidth))
      dstExtentYInBlocks := roundUpTo(as!u32(dstExtentY), as!u32(dstBlockHeight))

      for l in (0 .. region.srcSubresource.layerCount) {
        srcImageLevel := srcImageObject.Aspects[aspectBit].Layers[srcBaseLayer + l].Levels[srcMipLevel]
        dstImageLevel := dstImageObject.Aspects[aspectBit].Layers[dstBaseLayer + l].Levels[dstMipLevel]

        srcImageLevelWidthInBlocks := as!u64(roundUpTo(srcImageLevel.Width, as!u32(srcBlockWidth)))
        srcImageLevelHeightInBlocks := as!u64(roundUpTo(srcImageLevel.Height, as!u32(srcBlockHeight)))
        dstImageLevelWidthInBlocks := as!u64(roundUpTo(dstImageLevel.Width, as!u32(dstBlockWidth)))
        dstImageLevelHeightInBlocks := as!u64(roundUpTo(dstImageLevel.Height, as!u32(dstBlockHeight)))

        for z in (0 .. srcExtentZ) {
          for y in (0 .. srcExtentYInBlocks) {
            copySize := as!u64(srcExtentXInBlocks) * srcElementSize
            srcY := srcYStartInBlocks + as!u64(y)
            srcZ := srcZStart + as!u64(z)
            srcStart := ((((srcZ * srcImageLevelHeightInBlocks) + srcY) * srcImageLevelWidthInBlocks) + srcXStartInBlocks) * srcElementSize
            if len(srcImageLevel.Data) > 0 {
              read(srcImageLevel.Data[srcStart:srcStart+copySize])
            }
          }
        }
        for z in (0 .. dstExtentZ) {
          for y in (0 .. dstExtentYInBlocks) {
            copySize := as!u64(dstExtentXInBlocks) * dstElementSize
            dstY := dstYStartInBlocks + as!u64(y)
            dstZ := dstZStart + as!u64(z)
            dstStart := ((((dstZ * dstImageLevelHeightInBlocks) + dstY) * dstImageLevelWidthInBlocks) + dstXStartInBlocks) * dstElementSize
            if len(dstImageLevel.Data) > 0 {
              write(dstImageLevel.Data[dstStart:dstStart+copySize])
            }
          }
        }
      }
    }
  }
}

sub void dovkCmdBlitImage(ref!vkCmdBlitImageArgs args) {
  if !(args.SrcImage in Images) { vkErrorInvalidImage(args.SrcImage) }
  if !(args.DstImage in Images) { vkErrorInvalidImage(args.DstImage) }
  srcImageObject := Images[args.SrcImage]

  // The following read on coherent memory of the source image does not affect the data in imageLevel.Data, as they are different memory spaces.
  // But such a read is necessary if the backing memory of the source image is coherent, as we need the read observations on all memory changes
  // in order to replay correctly. However, as the UI's texture data comes from imageLevel.Data, just using the following call will not bring
  // the changes in coherent memory to the UI's texture view.
  readCoherentMemoryInImage(srcImageObject)
  trackVkCmdBlitImage(args)
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdBlitImage(
    VkCommandBuffer    commandBuffer,
    VkImage            srcImage,
    VkImageLayout      srcImageLayout,
    VkImage            dstImage,
    VkImageLayout      dstImageLayout,
    u32                regionCount,
    const VkImageBlit* pRegions,
    VkFilter           filter) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(srcImage in Images) {
      vkErrorInvalidImage(srcImage)
    } else {
      if !(dstImage in Images) {
        vkErrorInvalidImage(dstImage)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]
        args := new!vkCmdBlitImageArgs(
          SrcImage:        srcImage,
          SrcImageLayout:  srcImageLayout,
          DstImage:        dstImage,
          DstImageLayout:  dstImageLayout,
          Filter:          filter
        )

        regions := pRegions[0:regionCount]
        for i in (0 .. regionCount) {
          r := regions[i]
          args.Regions[as!u32(i)] = r
        }
        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdBlitImage))
        cmdBuf.BufferCommands.vkCmdBlitImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdBlitImage, mapPos)
      }
    }
  }
}

@internal
class RowLengthAndImageHeight {
  u32 RowLength
  u32 ImageHeight
}

sub RowLengthAndImageHeight getRowLengthAndImageHeight(VkBufferImageCopy region) {
  rowLength := switch region.bufferRowLength == 0 {
    case true:  region.imageExtent.width
    case false: region.bufferRowLength
  }
  imageHeight := switch region.bufferImageHeight == 0 {
    case true:  region.imageExtent.height
    case false: region.bufferImageHeight
  }
  return RowLengthAndImageHeight(rowLength, imageHeight)
}

@internal
class CopyImageLayout {
  u64 rowPitch    // in bytes
  u64 depthPitch  // in bytes
}

sub CopyImageLayout getCopyImageLayout(ref!ImageLevel lvl, TexelBlockSizePair texelSize, u64 elementSize) {
  ll := lvl.LinearLayout
  w := as!u64(roundUpTo(lvl.Width, texelSize.Width))
  h := as!u64(roundUpTo(lvl.Height, texelSize.Height))
  return switch ll == null {
    case true: CopyImageLayout(w * elementSize, w * h * elementSize)
    case false: CopyImageLayout(as!u64(ll.rowPitch), as!u64(ll.depthPitch))
  }
}

@spy_disabled
sub void copyImageBuffer(VkBuffer buffer, VkImage image, VkImageLayout layout, map!(u32, VkBufferImageCopy) regions, bool isSrcBuffer) {
  if !(image in Images) { vkErrorInvalidImage(image) }
  if !(buffer in Buffers) { vkErrorInvalidBuffer(buffer) }
  imageObject := Images[image]
  bufferObject := Buffers[buffer]
  format := imageObject.Info.Format

  depthElementSize := as!u64(getDepthElementSize(format, true))
  depthElementSizeInImage := as!u64(getDepthElementSize(format, false))
  // Iterate through regions
  n := len(regions)
  for i in (0 .. n) {
    region := regions[as!u32(i)]
    // The VkImageSubresourceLayer used for buffer image copy should specify only one aspect bit.
    aspectBits := unpackImageAspectFlags(imageObject, region.imageSubresource.aspectMask)
    if(len(aspectBits) != 1) { vkErrorInvalidImageAspect(imageObject.VulkanHandle,  as!VkImageAspectFlagBits(region.imageSubresource.aspectMask)) } else {
    aspectBit := aspectBits[0]
    isPackedDepth := (aspectBit == VK_IMAGE_ASPECT_DEPTH_BIT) && ((format == VK_FORMAT_D24_UNORM_S8_UINT) || (format == VK_FORMAT_X8_D24_UNORM_PACK32))
    elementAndTexelBlockSize := getElementAndTexelBlockSizeForAspect(format, aspectBit)
    elementSize := switch (aspectBit) {
      case VK_IMAGE_ASPECT_COLOR_BIT,
           VK_IMAGE_ASPECT_STENCIL_BIT:
          as!u64(elementAndTexelBlockSize.ElementSize)
      case VK_IMAGE_ASPECT_DEPTH_BIT:
          depthElementSize
      default:
          as!u64(1)
    }

    rowLengthAndImageHeight := getRowLengthAndImageHeight(region)
    rowLength := (as!u64(rowLengthAndImageHeight.RowLength / elementAndTexelBlockSize.TexelBlockSize.Width))
    imageHeight := (as!u64(rowLengthAndImageHeight.ImageHeight / elementAndTexelBlockSize.TexelBlockSize.Height))
    layerSize := rowLength * imageHeight * elementSize
    zStart := as!u64(region.imageOffset.z)
    zEnd := zStart + as!u64(region.imageExtent.depth)
    yStart := as!u64(as!u32(region.imageOffset.y) / elementAndTexelBlockSize.TexelBlockSize.Height)
    yEnd := yStart + as!u64(region.imageExtent.height / elementAndTexelBlockSize.TexelBlockSize.Height)
    xStart := as!u64(as!u32(region.imageOffset.x) / elementAndTexelBlockSize.TexelBlockSize.Width)
    xEnd := xStart + as!u64(region.imageExtent.width / elementAndTexelBlockSize.TexelBlockSize.Width)
    // When multiple layers are specified in the buffer image copy region,
    // Vulkan assumes the data of all the layers are placed continuously in
    // the source buffer memory.
    for j in (0 .. region.imageSubresource.layerCount) {
      layerIndex := region.imageSubresource.baseArrayLayer + j
      bufferLayerOffset := (as!u64(j) * layerSize) + as!u64(region.bufferOffset)
      imageLevel := imageObject.Aspects[aspectBit].Layers[layerIndex].Levels[region.imageSubresource.mipLevel]
      imageLayout := getCopyImageLayout(imageLevel, elementAndTexelBlockSize.TexelBlockSize, elementSize)
      // Iterate through depths and rows to copy
      for z in (zStart .. zEnd) {
        zInExtent := z - zStart
        depthStartByte := z * imageLayout.depthPitch
        for y in (yStart .. yEnd) {
          yInExtent := y - yStart
          rowStartByte := depthStartByte + y * imageLayout.rowPitch
          rowStartBlockInExtent := ((zInExtent * imageHeight) + yInExtent) * rowLength
          if isPackedDepth {
            for x in (xStart .. xEnd) {
              imgStart := as!VkDeviceSize(rowStartByte + x * depthElementSizeInImage)
              rowStartInExtent := (rowStartBlockInExtent + x) * elementSize
              bufStart := as!VkDeviceSize(bufferLayerOffset + rowStartInExtent)
              readMemoryInBuffer(bufferObject, bufStart, as!VkDeviceSize(elementSize))
              // Discard the 4th byte in the buffer for current pixel.
              bufMemPieces := getBufferBoundMemoryPiecesInRange(bufferObject, bufStart, as!VkDeviceSize(depthElementSizeInImage))
              for _ , _ , piece in bufMemPieces {
                bufMemStart := piece.MemoryOffset
                bufMemEnd := bufMemStart + piece.Size
                imgPieceStart := (piece.ResourceOffset - bufStart) + imgStart
                imgPieceEnd := imgPieceStart + piece.Size
                if isSrcBuffer {
                  copy(imageLevel.Data[imgPieceStart:imgPieceEnd], piece.DeviceMemory.Data[bufMemStart:bufMemEnd])
                } else {
                  copy(piece.DeviceMemory.Data[bufMemStart:bufMemEnd], imageLevel.Data[imgPieceStart:imgPieceEnd])
                }
              }
            }
          } else {
            copySize := as!VkDeviceSize((xEnd - xStart) * elementSize)
            imgStart := rowStartByte + xStart * elementSize
            rowStartInExtent := rowStartBlockInExtent * elementSize
            bufStart := as!VkDeviceSize(bufferLayerOffset + rowStartInExtent)
            readMemoryInBuffer(bufferObject, bufStart, copySize)
            bufMemPieces := getBufferBoundMemoryPiecesInRange(bufferObject, bufStart, copySize)
            for _ , _ , piece in bufMemPieces {
              bufMemStart := piece.MemoryOffset
              bufMemEnd := bufMemStart + piece.Size
              imgPieceStart := as!u64(piece.ResourceOffset - bufStart) + imgStart
              imgPieceEnd := imgPieceStart + as!u64(piece.Size)
              if isSrcBuffer {
                copy(imageLevel.Data[imgPieceStart:imgPieceEnd], piece.DeviceMemory.Data[bufMemStart:bufMemEnd])
              } else {
                copy(piece.DeviceMemory.Data[bufMemStart:bufMemEnd], imageLevel.Data[imgPieceStart:imgPieceEnd])
              }
            }
          }
        }
      }
    }
  }}
}

@internal
class vkCmdCopyBufferToImageArgs {
  VkBuffer                     SrcBuffer
  VkImage                      DstImage
  VkImageLayout                Layout
  map!(u32, VkBufferImageCopy) Regions
}


sub void dovkCmdCopyBufferToImage(ref!vkCmdCopyBufferToImageArgs args) {
  if (!args.SrcBuffer in Buffers) { vkErrorInvalidBuffer(args.SrcBuffer) } else {
    readCoherentMemoryInBuffer(Buffers[args.SrcBuffer])
    copyImageBuffer(args.SrcBuffer, args.DstImage, args.Layout, args.Regions, true)
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdCopyBufferToImage(
    VkCommandBuffer          commandBuffer,
    VkBuffer                 srcBuffer,
    VkImage                  dstImage,
    VkImageLayout            dstImageLayout,
    u32                      regionCount,
    const VkBufferImageCopy* pRegions) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(srcBuffer in Buffers) {
      vkErrorInvalidBuffer(srcBuffer)
    } else {
      if !(dstImage in Images) {
        vkErrorInvalidImage(dstImage)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]

        regions := pRegions[0:regionCount]
        read(regions)
        args := new!vkCmdCopyBufferToImageArgs(srcBuffer, dstImage, dstImageLayout)
        for i in (0 .. regionCount) {
          r := regions[i]
          args.Regions[as!u32(i)] = r
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdCopyBufferToImage))
        cmdBuf.BufferCommands.vkCmdCopyBufferToImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdCopyBufferToImage, mapPos)
      }
    }
  }
}

@internal
class vkCmdCopyImageToBufferArgs {
  VkImage                      SrcImage
  VkImageLayout                SrcImageLayout
  VkBuffer                     DstBuffer
  map!(u32, VkBufferImageCopy) Regions
}

sub void dovkCmdCopyImageToBuffer(ref!vkCmdCopyImageToBufferArgs args) {
  if (!args.SrcImage in Images) { vkErrorInvalidImage(args.SrcImage) } else {
    readCoherentMemoryInImage(Images[args.SrcImage])
    copyImageBuffer(args.DstBuffer, args.SrcImage, args.SrcImageLayout, args.Regions, false)
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdCopyImageToBuffer(
    VkCommandBuffer          commandBuffer,
    VkImage                  srcImage,
    VkImageLayout            srcImageLayout,
    VkBuffer                 dstBuffer,
    u32                      regionCount,
    const VkBufferImageCopy* pRegions) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(dstBuffer in Buffers) {
      vkErrorInvalidBuffer(dstBuffer)
    } else {
      if !(srcImage in Images) {
        vkErrorInvalidImage(srcImage)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]

        regions := pRegions[0:regionCount]
        args := new!vkCmdCopyImageToBufferArgs(
          SrcImage:        srcImage,
          SrcImageLayout:  srcImageLayout,
          DstBuffer:       dstBuffer,
        )
        for i in (0 .. regionCount) {
          r := regions[i]
          args.Regions[as!u32(i)] = r
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdCopyImageToBuffer))
        cmdBuf.BufferCommands.vkCmdCopyImageToBuffer[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdCopyImageToBuffer, mapPos)
      }
    }
  }
}

@internal class vkCmdUpdateBufferArgs {
  VkBuffer     DstBuffer
  VkDeviceSize DstOffset
  VkDeviceSize DataSize
  u8[]         Data
}

@spy_disabled
sub void dovkCmdUpdateBuffer(ref!vkCmdUpdateBufferArgs args) {
  if !(args.DstBuffer in Buffers) { vkErrorInvalidBuffer(args.DstBuffer) }
  Buffers[args.DstBuffer].LastBoundQueue = LastBoundQueue
  buff := Buffers[args.DstBuffer]
  bufPieces := getBufferBoundMemoryPiecesInRange(buff, args.DstOffset, args.DataSize)
  for _ , _ , p in bufPieces {
    srcOffset := p.ResourceOffset - args.DstOffset
    size := min!VkDeviceSize(p.Size, as!VkDeviceSize(len(args.Data)) - srcOffset)
    copy(buff.Memory.Data[p.MemoryOffset:p.MemoryOffset + size], args.Data[srcOffset:srcOffset + size])
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdUpdateBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer        dstBuffer,
    VkDeviceSize    dstOffset,
    VkDeviceSize    dataSize,
    const void*     pData) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(dstBuffer in Buffers) {
      vkErrorInvalidBuffer(dstBuffer)
    } else {
      cmdBuf := CommandBuffers[commandBuffer]

      args := new!vkCmdUpdateBufferArgs(
        dstBuffer,
        dstOffset,
        dataSize,
      )
      args.Data = clone(as!u8*(pData)[0:dataSize])

      mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdUpdateBuffer))
      cmdBuf.BufferCommands.vkCmdUpdateBuffer[mapPos] = args

      AddCommand(commandBuffer, cmd_vkCmdUpdateBuffer, mapPos)
    }
  }
}

@internal
class vkCmdFillBufferArgs {
  VkBuffer     Buffer
  VkDeviceSize DstOffset,
  VkDeviceSize Size
  u32          Data
}

@spy_disabled
sub void dovkCmdFillBuffer(ref!vkCmdFillBufferArgs args) {
  if !(args.Buffer in Buffers) { vkErrorInvalidBuffer(args.Buffer) }
  buf := Buffers[args.Buffer]
  bufPieces := getBufferBoundMemoryPiecesInRange(buf, args.DstOffset, args.Size)
  for _ , _ , p in bufPieces {
    if as!VkDeviceSize(len(p.DeviceMemory.Data)) >= (p.MemoryOffset + p.Size) {
      write(p.DeviceMemory.Data[p.MemoryOffset: p.MemoryOffset + p.Size])
    }
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdFillBuffer(
    VkCommandBuffer commandBuffer,
    VkBuffer        dstBuffer,
    VkDeviceSize    dstOffset,
    VkDeviceSize    size,
    u32             data) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(dstBuffer in Buffers) {
      vkErrorInvalidBuffer(dstBuffer)
    } else {
      cmdBuf := CommandBuffers[commandBuffer]

      args := new!vkCmdFillBufferArgs(
        dstBuffer,
        dstOffset,
        size,
        data
      )

      mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdFillBuffer))
      cmdBuf.BufferCommands.vkCmdFillBuffer[mapPos] = args

      AddCommand(commandBuffer, cmd_vkCmdFillBuffer, mapPos)
    }
  }
}

@internal
class vkCmdClearColorImageArgs {
  VkImage                            Image
  VkImageLayout                      ImageLayout
  VkClearColorValue                  Color
  map!(u32, VkImageSubresourceRange) Ranges
}

@spy_disabled
sub void dovkCmdClearColorImage(ref!vkCmdClearColorImageArgs args) {
  if !(args.Image in Images) { vkErrorInvalidImage(args.Image) }
  image := Images[args.Image]
  for _, _, r in args.Ranges {
    writeImageSubresource(image, r)
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdClearColorImage(
    VkCommandBuffer                commandBuffer,
    VkImage                        image,
    VkImageLayout                  imageLayout,
    const VkClearColorValue*       pColor,
    u32                            rangeCount,
    const VkImageSubresourceRange* pRanges) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(image in Images) {
      vkErrorInvalidImage(image)
    } else {
      if pColor == null {
        vkErrorNullPointer("VkClearColorValue")
      } else {
        cmdBuf := CommandBuffers[commandBuffer]
        color := pColor[0]
        ranges := pRanges[0:rangeCount]
        args := new!vkCmdClearColorImageArgs(
          Image:        image,
          ImageLayout:  imageLayout,
          Color:        color,
        )
        for i in (0 .. rangeCount) {
          args.Ranges[as!u32(i)] = ranges[i]
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdClearColorImage))
        cmdBuf.BufferCommands.vkCmdClearColorImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdClearColorImage, mapPos)
      }
    }
  }
}

@internal
class vkCmdClearDepthStencilImageArgs {
  VkImage                            Image
  VkImageLayout                      ImageLayout
  VkClearDepthStencilValue           DepthStencil
  map!(u32, VkImageSubresourceRange) Ranges
}

@spy_disabled
sub void dovkCmdClearDepthStencilImage(ref!vkCmdClearDepthStencilImageArgs args) {
  if !(args.Image in Images) { vkErrorInvalidImage(args.Image) }
  image := Images[args.Image]
  for _, _, r in args.Ranges {
    writeImageSubresource(image, r)
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdClearDepthStencilImage(
    VkCommandBuffer                 commandBuffer,
    VkImage                         image,
    VkImageLayout                   imageLayout,
    const VkClearDepthStencilValue* pDepthStencil,
    u32                             rangeCount,
    const VkImageSubresourceRange*  pRanges) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(image in Images) {
      vkErrorInvalidImage(image)
    } else {
      if pDepthStencil == null {
        vkErrorNullPointer("VkClearDepthStencilValue")
      } else {
        cmdBuf := CommandBuffers[commandBuffer]
        depthStencil := pDepthStencil[0]
        ranges := pRanges[0:rangeCount]
        args := new!vkCmdClearDepthStencilImageArgs(
          Image:         image,
          ImageLayout:   imageLayout,
          DepthStencil:  depthStencil,
        )
        for i in (0 .. rangeCount) {
          args.Ranges[as!u32(i)] = ranges[i]
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdClearDepthStencilImage))
        cmdBuf.BufferCommands.vkCmdClearDepthStencilImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdClearDepthStencilImage, mapPos)
      }
    }
  }
}

@internal
class vkCmdClearAttachmentsArgs {
  map!(u32, VkClearAttachment) Attachments
  map!(u32, VkClearRect)       Rects
}

@spy_disabled
sub void dovkCmdClearAttachments(ref!vkCmdClearAttachmentsArgs args) {
  useRenderPass()
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdClearAttachments(
    VkCommandBuffer          commandBuffer,
    u32                      attachmentCount,
    const VkClearAttachment* pAttachments,
    u32                      rectCount,
    const VkClearRect*       pRects) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    cmdBuf := CommandBuffers[commandBuffer]

    args := new!vkCmdClearAttachmentsArgs()
    attachments := pAttachments[0:attachmentCount]
    rects := pRects[0:rectCount]
    for i in (0 .. attachmentCount) {
      args.Attachments[as!u32(i)] = attachments[i]
    }
    for i in (0 .. rectCount) {
      args.Rects[as!u32(i)] = rects[i]
    }

    mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdClearAttachments))
    cmdBuf.BufferCommands.vkCmdClearAttachments[mapPos] = args

    AddCommand(commandBuffer, cmd_vkCmdClearAttachments, mapPos)
  }
}

@internal class vkCmdResolveImageArgs {
  VkImage                   SrcImage      ,
  VkImageLayout             SrcImageLayout,
  VkImage                   DstImage      ,
  VkImageLayout             DstImageLayout,
  map!(u32, VkImageResolve) ResolveRegions
}

sub void dovkCmdResolveImage(ref!vkCmdResolveImageArgs args) {
  if !(args.SrcImage in Images) { vkErrorInvalidImage(args.SrcImage) }
  if !(args.DstImage in Images) { vkErrorInvalidImage(args.DstImage) }
  for _ , _ , r in args.ResolveRegions {
    srcRange := VkImageSubresourceRange(
      r.srcSubresource.aspectMask,
      r.srcSubresource.mipLevel,
      1,
      r.srcSubresource.baseArrayLayer,
      r.srcSubresource.layerCount)
    dstRange := VkImageSubresourceRange(
      r.dstSubresource.aspectMask,
      r.dstSubresource.mipLevel,
      1,
      r.dstSubresource.baseArrayLayer,
      r.dstSubresource.layerCount)

    src := Images[args.SrcImage]
    dst := Images[args.DstImage]

    updateImageQueue(src, srcRange)
    readCoherentMemoryInImage(src)
    readImageSubresource(src, srcRange)
    updateImageQueue(dst, dstRange)
    writeImageSubresource(dst, dstRange)
  }
}

@threadSafety("app")
@indirect("VkCommandBuffer", "VkDevice")
@threadsafe
cmd void vkCmdResolveImage(
    VkCommandBuffer       commandBuffer,
    VkImage               srcImage,
    VkImageLayout         srcImageLayout,
    VkImage               dstImage,
    VkImageLayout         dstImageLayout,
    u32                   regionCount,
    const VkImageResolve* pRegions) {
  if !(commandBuffer in CommandBuffers) {
    vkErrorInvalidCommandBuffer(commandBuffer)
  } else {
    if !(srcImage in Images) {
      vkErrorInvalidImage(srcImage)
    } else {
      if !(dstImage in Images) {
        vkErrorInvalidImage(dstImage)
      } else {
        cmdBuf := CommandBuffers[commandBuffer]
        args := new!vkCmdResolveImageArgs(
          SrcImage:        srcImage,
          SrcImageLayout:  srcImageLayout,
          DstImage:        dstImage,
          DstImageLayout:  dstImageLayout
        )
        regions := pRegions[0:regionCount]
        for i in (0 .. regionCount) {
          args.ResolveRegions[as!u32(i)] = regions[i]
        }

        mapPos := as!u32(len(cmdBuf.BufferCommands.vkCmdResolveImage))
        cmdBuf.BufferCommands.vkCmdResolveImage[mapPos] = args

        AddCommand(commandBuffer, cmd_vkCmdResolveImage, mapPos)
      }
    }
  }
}
